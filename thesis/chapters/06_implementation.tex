% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Implementation}\label{chapter:implementation}

As part of our work, we implemented the algorithms described in \cref{chapter:offline_algorithms} and \cref{chapter:online_algorithms}. Our implementation is written in Rust and has Python bindings to interact with some components~\cite{Huebotter2021_2, Huebotter2021_3}. Detailed documentation of the implementation is available~\cite{Huebotter2021_4}. In this chapter, we discuss the general architecture and the points of focus of our implementation.

\section{Architecture}\label{section:implementation:architecture}

Our implementation is separated into four main components. First, a component that encompasses the implementation of the general problems described in \cref{chapter:theory}. Second, a related component containing the implementations of the offline and online algorithms from \cref{chapter:offline_algorithms} and \cref{chapter:online_algorithms}, respectively. Third, a component including abstractions to generate and update problem instances over time (referred to as \emph{models}\index{models}). This includes the models of data centers described in \cref{chapter:application}. Fourth, a component that implements the algorithms' practical use. Among other things, this component is used to execute online algorithms in real-time by sequentially updating the underlying problem instance as new information becomes available (referred to as \emph{streaming}\index{streaming} an online algorithm).

\subsection{Problems and Reductions}

This component includes data structures representing instances of the problems introduced in \cref{chapter:theory}. Note-worthy aspects are the definition of norms for SCO and hitting costs for SCO, SSCO, and SBLO. We also implemented the reductions from SLO to SBLO, SBLO to SSCO, and SSCO to SCO.

\paragraph{Norms} Our implementation includes the Manhattan norm, Euclidean norm, Mahalanobis norm, and a dimension-dependently scaled variant of the Manhattan norm, which is used in the reduction from SSCO to SCO. We also include implementations of the square of a norm as well as the dual of a norm.

\paragraph{Hitting Costs} The primary data structure used across SCO, SSCO, and SBLO is the definition of hitting costs. Here, our implementation has to allow for sequentially arriving subsets of the hitting cost. Consider the example of an online algorithm with a prediction window $w$. Then, at each time slot $\tau$, the algorithm expects to receive a hitting cost with domain $[\tau : \tau + w]$ which conflicts with previous and subsequent hitting costs. To complicate the matter further, offline algorithms only require a single hitting cost covering the entire domain $[T]$.

In our implementation, we refer to these hitting costs, which may only cover definitions of the hitting cost for a subset of all time slots as \emph{single hitting costs}\index{single hitting cost}. In the online setting, the domain of a single hitting cost may cover future time slots, in which case the hitting cost is uncertain. From our discussion of predictions in \cref{section:online_algorithms:md:predictions:making_predictions}, it naturally follows to model the distribution of hitting costs for a future time slot as a vector of samples that can then be used to estimate the density. Thus, a single cost function arriving at time slot $\tau$ is formally described as a function $\chi_{\tau} : [T] \times \mathcal{S} \to \bigcup_{n=1}^{\infty} \mathbb{R}_{\geq 0}^n$ mapping a time slot $t \in [T]$ and some point $x$ in the space $\mathcal{S}$ to a prediction with a varying sample size $n$. In the case of a certain prediction, the sample size is $1$. For SCO and SSCO we set $\mathcal{S} = \mathcal{X}$ while for SBLO we set $\mathcal{S} = \mathbb{R}$.

We implemented the hitting cost $f_t(x)$ using a B-Tree-Map\footnote{A B-Tree-Map is a map based on a B-Tree balancing cache-efficiency and search performance~\cite{BTreeMap}} mapping the time slot of their arrival to single hitting costs. Crucially, there need not be a single hitting cost for every time slot, as the example of an offline algorithm illustrates. The concrete single hitting cost is determined by choosing the last single hitting cost arriving during a time slot in $[t]$. In an online setting, this ensures that if $t$ is in the future, the current single hitting cost is used, and if $t$ is in the past, the single hitting cost from time slot $t$ (or the closest previous single hitting cost) is used.

\subsection{Algorithms}

The algorithms component encompasses the implementation of all offline and online algorithms described in \cref{chapter:offline_algorithms} and \cref{chapter:online_algorithms}. For both classes of algorithms, we defined a common interface.

\paragraph{Offline} An offline algorithm receives as input a problem instance and some algorithm-specific options. It returns an arbitrary data structure that can be used to obtain the determined schedule. In our implementation, we generalized the algorithms slightly so as to support the following uses:

First, we adapted the graph-based algorithms for SSCO to support inverted movement costs, i.e., paying the switching cost for shutting down a server rather than powering up a server. Second, we adapted all algorithms to allow for computing the $\alpha$-unfair optimal offline solution where movement costs are scaled by a factor $\alpha$. Third, we adapted the general algorithm for the multi-dimensional fractional case to support computing the $L$-constrained optimal offline solution where movement costs are upper-bounded by the constant $L$. The $L$-constrained optimal offline solution cannot easily be computed using the graph-based approaches for the integral case as this additional constraint prevents the application of Bellman's optimality principle to find a shortest path using dynamic programming. Fourth, we extended the implementations to allow starting from an arbitrary initial time slot. Fifth, we adapted the uni-dimensional optimal graph search (\cref{alg:ud:optimal_graph_search}) to support arbitrary initial configurations in the first time slot.

Some of these extensions are required to implement some online algorithms, and others were merely added for analysis purposes. We also provide functions to compute the static fractional and integral optima.

\paragraph{Online} An online algorithm receives as input a problem instance, the current time slot $\tau$, the schedule for all previous time slots, some algorithm-specific memory, and some algorithm-specific options. The algorithm returns the configuration for time slot $\tau$ as well as the updated memory. The practical use of online algorithms is described in greater detail in \cref{section:implementation:architecture:streaming}.

\subsection{Models}

In practice, it is not very useful to generate and update the problem instances directly. In the application of right-sizing data centers, we have discussed models of operating costs and switching costs in detail in \cref{chapter:application}. These models can be used to generate instances of the problems discussed in \cref{chapter:theory}. This approach is not limited to the application of right-sizing data centers. A model is a data structure with associated functions to produce an associated problem instance and update an existing problem instance online. As seen in the example of right-sizing data centers, these generators may require additional inputs, which are provided as the load profiles for each time slot. We refer to the inputs required for the initial generation of a problem instance as \emph{offline inputs}\index{offline inputs} and the inputs required to update a problem instance online as \emph{online inputs}\index{online inputs}. Offline inputs encapsulate information for all time slots with respect to some time horizon $[T]$ whereas online inputs for some time slot $\tau$ encapsulate information for the current time slot $\tau$ as well as all time slots in the prediction window $[\tau + 1 : \tau + w]$.

In the application of right-sizing data centers, an offline input is a vector of load profiles $\mathcal{I} = (\lambda_1, \dots, \lambda_T)$ with $\lambda_t \in \mathbb{N}_0^e$ for all $t \in [T]$. In contrast, an online input is a vector of predicted load profiles $\mathcal{I} = (\lambda_{\tau}, \mathcal{P}_{\tau + 1}, \dots, \mathcal{P}_{\tau + w})$ with $\lambda_{\tau} \in \mathbb{N}_0^e$ and where $\mathcal{P}_t \in \left(\bigcup_{n=1}^{\infty} \mathbb{N}_0^n\right)^e$ is a \emph{predicted load profile}\index{predicted load profile}, i.e., a vector of predicted loads for each job type. Similar to our implementation of single hitting costs, we use a varying number of $n$ samples to describe the distribution of predicted loads. The load profile for the current time slot $\tau$ is certain.

We observe that given a predicted load profile $\mathcal{P}_t$ with $n_i$ samples of loads with type $i \in [e]$, the sampled load profiles are all combinations of the samples of individual loads, resulting in $\prod_{i=1}^e n_i$ sampled load profiles. To reduce the number of considered samples, we randomly select $n$ sampled loads of each type to produce $n$ load profile samples. This approach is reasonable as the samples of the individual loads were only an approximate prediction, to begin with.

Another core element of a model are \emph{model outputs}\index{model outputs}. These are results that are returned from the model, which reach beyond simply some cost. For our data center model, we implemented outputs to return the energy cost instead of the revenue loss and the determined optimal assignment of jobs to server types.

The implementation of our data center model consists of separate models for energy consumption, energy cost, delay, revenue loss, and switching cost, which can be combined in various ways to obtain a concrete model of a data center or a network of data centers. For the generation of instances of SBLO, the model must be limited to a single location, source, and job type. For the generation of instances of SLO, the model further assumes full utilization of every active server during each time slot and averages the energy cost over the time horizon.

Crucially, we assume in our model that job arrivals fall precisely onto the beginning of new time slots. Without this approximation, we cannot ensure that all arriving jobs can be completed by the end of the time slot. In practice, this requires matching jobs to time slots either by delaying them to the next time slots (in which case they are available from the beginning) or simply assuming they are available from the beginning of the current time slot.

\subsection{Streaming and Practical Use}\label{section:implementation:architecture:streaming}

Using an offline algorithm is relatively straightforward. Given a model and offline inputs, we can generate a problem instance that the offline algorithm can then solve. With online algorithms, this becomes more involved. For example, some uses require the immediate streaming of an online algorithm from an initial to a final time slot. This is required by the Lazy Budgeting algorithm (\cref{alg:md:lazy_budgeting:sblo_c}), which streams an intermediate online algorithm for the sub time slots of the current time slot.

However, in general, the challenge in streaming an online algorithm is to remember the algorithm's state with infrequent incoming iterations (once per time slot). To this end, we implemented a simple client-server architecture. Here, the server runs in the background and remembers the problem instance and state of the algorithm. Whenever new information arrives, the client requests the next iteration from the server. On initialization of the server, the online algorithm can be streamed up to the current time slot given previous offline inputs. This architecture has two main benefits: First, the responsibility for memorizing the problem instance and state of the algorithm is offloaded entirely to the server. Second, the initialization of the server only requires a model and (optionally) an offline input. Requesting the next iteration only requires the relevant offline input. In particular, the problem instance remains opaque, drastically simplifying the interaction with the interface and reducing the amount of data that needs to be remembered, and serialized, sent, and deserialized from the client to the server. This simplification also makes it feasible to stream an online algorithm relying entirely on Python bindings.

\section{Focuses}

We now turn to describe more general aspects of our implementation.

\subsection{Adaptability}

A central point of focus was to maximize the adaptability and general applicability of our implementation. More concretely, we focused on minimizing the number of cross-dependencies between the components described in \cref{section:implementation:architecture} to maximize the reusability across all components of the architecture. For example, an entirely new application can be supported solely by implementing a new model. Once a new algorithm is implemented, it can immediately be substituted for any other algorithm using any previously implemented model while benefiting from the infrastructure built around streaming online algorithms. This allows for faster prototyping of new algorithms while assessing their practical performance, particularly when using predictions. Also, this allows determining which algorithm performs best in a concrete application instance.

Moreover, using the client-server architecture, algorithms for smoothed online convex optimization can be utilized without much effort in any practical application. As the implementation is in Rust, it can be interfaced with any other programming language. For our case studies in \cref{chapter:case_studies}, we already implemented Python bindings~\cite{Huebotter2021_3}.

\subsection{Efficiency}

Next to the strong safety guarantees of Rust, the main benefit of an implementation in Rust is its memory efficiency and speed. Rust achieves similar performance than C or C++~\cite{Benchmarksgame, Rust, Perkel2020}. At the same time, Rust is readable and allows for high-level abstractions and polymorphism, which we use heavily to maximize adaptability.

In our implementation, we heavily parallelize tasks to achieve optimal performance~\cite{Matsakis2015}. For example, we parallelize calculating hitting costs for multiple predicted samples or determining the optimal predecessor of a vertice in iterations of the dynamic program finding a shortest path in a graph.

\subsection{Numeric Computations and Rounding}

In implementations involving numeric computations to some precision $\epsilon$ and frequent flooring or ceiling operations, it is essential to round numeric results to precision; otherwise, the results are not numerically stable. In our experimens, we use a precision of $\epsilon = 10^{-2}$, which performs well when results are rounded to integral solutions. For example, if the result of some numeric computation with precision epsilon is $10^{-3}$, which is then ceiled, we would falsely obtain $1$ as the result if we did not apply the precision to the result before proceeding with the algorithm.

For convex programs, we additionally interpret $\epsilon$ as relative to the absolute value of the optimization to maintain good performance.