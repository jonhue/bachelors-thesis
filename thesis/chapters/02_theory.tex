% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Theory}\label{chapter:theory}

In this chapter, we introduce the theoretical foundations for our subsequent work. We begin by formally introducing the metrics we use to assess the performance of the discussed algorithms. In the following, we introduce the problem of smoothed convex optimization and related problems that the examined algorithms address.

\section{Performance Metrics}\label{section:theory:performance_metrics}

We say that an algorithm is \textit{optimal} with respect to some performance metric if given its information it achieves an optimal score in the given metric. Crucially, optimality depends on the information given to the algorithm. We thus say that an offline algorithm of a minimization problem is optimal if its result always incurs the smallest possible cost while satisfying the given constraints. In contrast, an optimal online algorithm must not necessarily return the optimal offline solution. In fact, in many cases, online algorithms must necessarily perform worse than optimal offline algorithms due to the lack of provided information (in our case, the convex cost functions arrive over time). Naturally, these performance metrics also inform parts of our experimental analysis performed in \autoref{chapter:experiments}.

\subsection{Approximations}

We begin by considering the offline case. In most cases, we seek to find optimal solutions to the offline problem. However, for some problems where the computational complexity of optimal solutions is high for large instances, it is beneficial to consider efficient algorithms that achieve close to optimal performance motivating the definition of approximation algorithms. Note that we limit our definitions of performance metrics to minimization problems.

\begin{definition}
An \textit{$\alpha$-approximation algorithm} for a minimization problem $c$ is a polynomial time algorithm $ALG$ that for all instances of the problem produces a solution whose value is within a factor of $\alpha$ of the value of an optimal solution $OPT$, i.e. $c(ALG) \leq \alpha \cdot c(OPT)$. \cite{Williamson2011}.
\end{definition}

In other words, an $\alpha$-approximation guarantees that its results are at most a factor of $\alpha$ worse than the optimal solution. The integral smoothed convex optimization problem is such an example where important progress on approximation algorithms has recently been made by \citeauthor*{Kappelmann2017} and \citeauthor*{Albers2021_2} \cite{Kappelmann2017, Albers2021_2}.

\subsection{Competitiveness}

For online algorithms it is natural to consider an adaptation of the idea of approximation algorithms. Here, we compare the result of an online algorithm with the optimal offline solution.

\begin{definition}
A $\rho(T)$-competitive online algorithm for a minimization problem $c$ is an algorithm $ALG$ that for all instances of the problem produces a solution whose value is within a factor of $\rho(T)$ of the value of an optimal offline solution $OPT$, i.e. $c(ALG) \leq \rho(T) \cdot c(OPT)$.
\end{definition}

We observe that this definition is analogous to our earlier definition of approximation algorithms in the offline case. However, in contrast to approximation algorithms where the limiting factor was the complexity of the algorithm, the competitiveness of online algorithms is fundamentally restricted by the information available to an online algorithm compared to its offline variants. In the case of smoothed convex optimization, considerable work has focused on finding online algorithms with a constant competitive ratio in the number of dimensions $d$.

\subsection{Regret}

Regret is another approach to measuring the performance of online algorithms.

\begin{definition}
The (static) regret of an online algorithm $ALG$ for a minimization problem $c$ is $\rho(T)$ if for all instances of the problem the difference between the result of the algorithm and the static optimal offline solution $OPT_s$ does not exceed $\rho(T)$, i.e. $c(ALG) - c(OPT_s) \leq \rho(T)$.
\end{definition}

Commonly, the literature considers this definition of regret where the online algorithm is compared against a static offline solution, i.e. a solution where the agent is not allowed to move in the decision space. We say that an algorithm achieves \textit{no-regret} if $\rho$ is sublinear in the time horizon $T$.

Ideally, online algorithms perform well with respect to the competitive ratio and regret. In other words, our online algorithms should both perform well compared against an agent that is moving in the decision space with perfect knowledge of the future (competitive ratio) and perform well against an agent that picks one optimal location in the decision space. In the example of dynamically right-sizing a data center, our algorithms are obviously required to outperform a static number of servers. In contrast, to minimize energy waste and revenue loss, the strategies proposed by our algorithms must be as close as possible to the optimal dynamic strategies.

However, \citeauthor*{Andrew2015} proved that no online algorithm for smoothed convex optimization can simultaneously achieve a constant competitive ratio and no-regret even when $d = 1$ and cost functions are linear \cite{Andrew2015}. For no-regret algorithms, the competitive ratio can be arbitrarily poor by oscillating the dynamic optimal solution between two points in the decision space. The no-regret algorithm will approach a static optimum which itself can be arbitrarily worse than the dynamic optimum. In contrast, a constant-competitive algorithm generally sticks to a point in the decision space until it knows that the cost of movement are outweighed by the reduced cost of some other point that it then moves to. Hence, for constant-competitive algorithms, the regret can be arbitrarily large as the algorithm oscillates between the two points in the decision space, in each step having an arbitrary distance to the static optimum. [TODO: add figure]

There thus exist many variants of regret and the competitive ratio that are used to bridge between the two metrics. One approach is to consider an additive variant of the competitive ratio which is called \textit{competitive difference}.

\begin{definition}
The competitive difference of an online algorithm $ALG$ for a minimization problem $c$ is $\rho(T)$ if for all instances of the problem the difference between the result of the algorithm and the dynamic optimal offline solution $OPT$ does not exceed $\rho(T)$, i.e. $c(ALG) - c(OPT) \leq \rho(T)$ \cite{Chen2015}.
\end{definition}

This definition is also known as \textit{dynamic regret} \cite{Chen2018}. We next define a variant of regret that bridges between static and dynamic regret.

\begin{definition}
The $L$-constrained dynamic regret of an online algorithm $ALG$ for a minimization problem $c$ is $\rho(T)$ if for all instances of the problem the difference between the result of the algorithm and the $L$-constrained optimal offline solution $OPT_L$ does not exceed $\rho(T)$, i.e. $c(ALG) - c(OPT_L) \leq \rho(T)$ \cite{Chen2018}.

The $L$-constrained optimal offline solution minimizes $c$ subject to the additional constraint \begin{align*}
    \sum_{t=1}^T \norm{x_t - x_{t-1}} \leq L.
\end{align*}
\end{definition}

We now observe that given the optimal offline solution $OPT$ with schedule $x_t^*$, the $l$-constrained dynamic regret is equivalent to dynamic regret for $l = \sum_{t=1}^T \norm{x_t^* - x_{t-1}^*}$. The literature also considers other metrics such as the \textit{$\alpha$-unfair competitive ratio} which are very similar to $L$-constrained dynamic regret \cite{Andrew2015}.

\section{Problems}

Now that we have an overview over the commonly used performance metrics, we introduce the problems that we consider in this work. We initially state the problems as offline problems but as all problems follow the same structure their online variant simply provides one of the convex cost functions at every time step. All other problem variables --- except for the time horizon $T$ --- such as the switching cost that penalizes movement in the decision space are known from the beginning.

\subsection{Smoothed Convex Optimization}

We begin by formally introducing the most general problem we consider and which we already motivated in \autoref{chapter:introduction}.

\begin{problem}[Smoothed Convex Optimization (SCO)]
Given a time horizon $T \in \mathbb{N}$, a convex decision space $\mathcal{X} \subset \mathbb{R}^d$, a norm $\norm{\cdot}$ on $\mathbb{R}^d$, and a sequence of non-negative convex functions $f_t$ for $t \in [T]$ with $f_t(x) = \infty$ for all $x \not\in \mathcal{X}$, find $x \in \mathcal{X}$ minimizing \begin{align*}
    c_{SCO}(x) = \sum_{t=1}^T f_t(x_t) + \norm{x_t - x_{t-1}}
\end{align*}
where $x_0 = \mathbf{0}$.
\end{problem}

In many practical applications of Smoothed Convex Optimization, we seek to find integral solutions minimizing hitting and switching costs. This is especially true within the context of resource allocation, for example for right-sizing data centers, where our resources are discrete. This observation motivates the definition of the following variant of SCO.

\begin{problem}[Integral Smoothed Convex Optimization (Int-SCO)]
We define Integral Smoothed Convex Optimization analogously to SCO with the added restriction that the points $x$ in $d$-dimensional space must be discrete, that is $\mathcal{X} \subset \mathbb{Z}^d$.
\end{problem}

In \autoref{chapter:introduction}, we have seen that Int-SCO is subsumed by Metrical Task Systems. However, it was shown that in general the competitiveness of deterministic and randomized algorithms for Metrical Task Systems must be proportional to the size of the decision space \cite{Blum1992, Borodin1992}. Further, \citeauthor*{Chen2018} have shown that the competitiveness of any online algorithm for SCO is lower bounded by $\Omega(\sqrt{d})$ \cite{Chen2018}. Therefore, many of the online algorithms for SCO that we examine in \autoref{chapter:online_algorithms} further restrict the classes of hitting costs and switching costs.

In the \textit{ski rental problem} skis can be bought for a cost of $b$ units or rented for a cost of one unit per day. Each day of the ski season the agent has to decide whether to rent the skis or end the sequence of decisions by buying the skis without knowing how long the ski season will last \cite{Shah2021}. Consider the uni-dimensional decision space $\{0,b\}$, the $\ell_2$-norm as switching cost, and the sequence of hitting costs $f_t(0) = 1$ and $f_t(b) = 0$. The solution to this instance of SCO is a solution to the corresponding ski rental problem, yielding that the ski rental problem is a special case of SCO. \citeauthor*{Karlin1990} showed that the best competitive ratio attainable by a randomized algorithm is $e/(e-1) \approx 1.58$, giving a lower bound for the competitive ratio of online algorithms for SCO \cite{Karlin1990}.

\citeauthor*{Goel2019} proved that for $m$-strongly convex hitting costs with respect to the $\ell_2$ norm and $\ell_2$-squared switching costs, the optimal competitiveness of any online algorithm is $\mathcal{O}(1/\sqrt{m})$ as $m \downarrow 0$ \cite{Goel2019} We discuss hitting costs and switching costs of this shape in greater detail in \autoref{section:online_algorithms:descent_methods}. \citeauthor*{Bansal2015} have shown that in the uni-dimensional setting the optimal competitive ratio that can be attained by a deterministic memoryless algorithm for SCO is 3 \cite{Bansal2015}.

\subsubsection{Complexity of the Offline Problem}

We now want to examine the complexity of Int-SCO in the offline case. That is, we know all arriving convex cost functions $f_t$ in advance. We prove Int-SCO NP-hard for varying $d$ by giving a polynomial-time reduction from the Knapsack problem. In \autoref{section:theory:simplified_smoothed_convex_optimization} we extend this proof of NP-hardness to the Integral Simplified Smoothed Convex Optimization problem which further restricts the decision space and switching cost.

Given a set of items with an associated value and weight and an upper bound to the total weight, Knapsack is the problem of determining the number of copies of each item that maximizes the total value and conforms to the given upper bound on total weight. Formally we define Knapsack as follows.

\begin{problem}[Knapsack (KP)]
Given a number of items $n \in \mathbb{N}$, a value of each item $v \in \mathbb{N}^n$, a weight of each item $w \in \mathbb{N}^n$, and an upper bound to the total weight $W \in \mathbb{N}$, find $x \in \{0,1\}^n$ satisfying $\sum_{i = 1}^n w_i x_i \leq W$ and maximizing $\sum_{i=1}^n v_i x_i$.
\end{problem}

This variant of Knapsack is commonly called \textit{0-1 Knapsack} and restricts the number of copies of each item to be either 0 or 1. It is, however, easy to see that our proof can be generalized to a setting where we allow $x_i \in [m_i]_0$ for $m \in \mathbb{N}^n$. TODO et al. show that the Knapsack decision problem is NP-complete and that the Knapsack optimization problem is NP-hard.

Before reducing to Int-SCO, we reduce Knapsack to a related problem called Minimum Knapsack.

\begin{problem}[Minimum Knapsack (Min-KP)]
Given a number of items $n \in \mathbb{N}$, a cost of each item $c \in \mathbb{N}^n$, a utility of each item $u \in \mathbb{N}^n$, and a lower bound to the total utility $U \in \mathbb{N}$, find $x \in \{0,1\}^n$ satisfying $\sum_{i = 1}^n u_i x_i \geq U$ and minimizing $\sum_{i=1}^n c_i x_i$.
\end{problem}

\begin{lemma}
Min-KP is NP-hard.
\end{lemma}
\begin{proof}
We prove the lemma by giving a reduction from KP.

Let $\mathcal{I}_{KP} = (n, v, w, W)$ be an instance of KP. Let $\mathcal{I}_{Min-KP}(U) = (n, c, u, U)$ be an instance of Min-KP with $c = w$, and $u = v$. Hence, $\mathcal{I}_{Min-KP}(U)$ minimizes the total weight $\sum_{i=1}^n w_i x_i$ such that $\sum_{i=1}^n v_i x_i \geq U$.

By finding solutions to $\mathcal{I}_{Min-KP}(U)$ repeatedly for varying $U$, we determine the maximal $U$ such that $\sum_{i=1}^n w_i x_i \leq W$. We observe that $U$ is upper bounded by $n \cdot v_{max}$. If $U$ were greater than $n \cdot v_{max}$ we would have $\sum_{i=1}^n v_{max} x_i \geq \sum_{i=1}^n v_i x_i > n \cdot v_{max}$ which contradicts $x \in \{0,1\}^n$. Hence, we can use binary search to find $U$ in $\mathcal{O}(\log n + \log v_{max})$ iterations. The other direction works analogously.

We have seen a total, polynomial-time reduction from KP to Min-KP. Hence, Min-KP is NP-hard.
\end{proof}

Next we prove our main reduction from Min-KP to Int-SCO. To motivate this reduction, we first prove that the following (convex) integer optimization is in fact equivalent to Min-KP.

\begin{lemma}
\label{lemma:integer_minimization}
Let $\mathcal{I}_{Min-KP} = (n, c, u, U)$ be an instance of Min-KP. $x$ is the solution to $\mathcal{I}_{Min-KP}$ if and only if $x$ minimizes \begin{align*}
    c_{SCO}'(x) = \sum_{i=1}^n c_i x_i + M\left(U - \sum_{i=1}^n u_i x_i\right)^+
\end{align*} subject to $x \in \{0,1\}^n$ for some $M > \frac{n c_{max}}{u_{min}}$.
\end{lemma}
\begin{proof}
Suppose $x$ minimizes $c_{SCO}'(x)$. Now suppose $(U - \sum_{i=1}^n u_i x_i)^+ > 0$. Then $\sum_{i=1}^n u_i < U$ follows immediately. It is easy to see that if $x \equiv 1$, $\mathcal{I}$ has no solution because the lower bound on the utility $U$ is not met. Henceforth, we assume $x$ can be further increased. Then, $(U - \sum_{i=1}^n u_i x_i)^+ \geq u_{min}$. Therefore, $c_{SCO}'(x) > \sum_{i=1}^n c_i x_i + c_{max}$. We observe that $x$ is not optimal as $c_{SCO}'(x)$ could be minimized further by increasing $x$ such that $(U - \sum_{i=1}^n u_i x_i)^+ = 0$ since $\sum_{i=1}^n c_i x_i \leq n c_{max}$ holds for all $x$.

By leading our previous assumption to a contradiction, we conclude $(U - \sum_{i=1}^n u_i x_i)^+ = 0$ and therefore $U \leq \sum_{i=1}^n u_i x_i$. Further, $c_{SCO}'(x)$ minimizes $\sum_{i=1}^n c_i x_i$ for all remaining candidates for $x$. Hence, $x$ is the solution of $\mathcal{I}_{Min-KP}$.

On the other hand, suppose that $x$ is the solution to $\mathcal{I}_{Min-KP}$. Then $(U - \sum_{i=1}^n u_i x_i)^+ = 0$ and $\sum_{i=1}^n c_i x_i$ is minimized. Hence, $x$ minimizes $c_{SCO}'(x)$.
\end{proof}

For our construction we need that $c_{SCO}'$ is convex.

\begin{lemma}
\label{lemma:integer_minimization_convexity}
$c_{SCO}'$ is convex on $\{0,1\}^n$.
\end{lemma}
\begin{proof}
It is easy to see that $c_{SCO}'$ is continuous. Therefore, to show the convexity of $c_{SCO}'$ it suffices to prove midpoint-convexity, i.e. $c_{SCO}'\left(\frac{x+y}{2}\right) \leq \frac{c_{SCO}'(x)+c_{SCO}'(y)}{2}$ for all $x, y \in \mathbb{R}^n$.

To simplify the notation let $C(x) = \sum_{i=1}^n c_i x_i$ and let $U(x) = \sum_{i=1}^n u_i x_i$. To further simplify the notation we define $\frac{x+y}{2}$ to be applied component-wise to elements $i \in [n]$ of $x$ and $y$. We then obtain \small{
\begin{align*}
         &c_{SCO}'\left(\frac{x+y}{2}\right) \leq \frac{c_{SCO}'(x)+c_{SCO}'(y)}{2} \\
    \iff &C\left(\frac{x+y}{2}\right) + M\left(U - U\left(\frac{x+y}{2}\right)\right)^+ \leq \frac{C(x) + M(U - U(x))^+ + C(y) + M(U - U(y))^+}{2} \\
    \iff &C(x) + C(y) + 2M\left(U - U\left(\frac{x+y}{2}\right)\right)^+ \leq C(x) + M(U - U(x))^+ + C(y) + M(U - U(y))^+ \\
    \iff &2\left(U - U\left(\frac{x+y}{2}\right)\right)^+ \leq (U - U(x))^+ + (U - U(y))^+.
\end{align*}
}\normalsize

We immediately get the convexity of $U(\cdot)$ by the following equivalence. \begin{align*}
    U\left(\frac{x+y}{2}\right) &= \sum_{i=1}^n u_i \frac{x_i + y_i}{2} \\
                                &= \frac{\sum_{i=1}^n u_i x_i + \sum_{i=1}^n u_i y_i}{2} \\
                                &= \frac{U(x) + U(y)}{2}.
\end{align*}

Now, we consider three cases separately.

\begin{enumerate}
    \item If $U(x) > U$ and $U(y) > U$, then $U\left(\frac{x+y}{2}\right) > U$. Hence \begin{align*}
        2\left(U - U\left(\frac{x+y}{2}\right)\right)^+ = 0 = (U - U(x))^+ + (U - U(y))^+.
    \end{align*}
    \item If $U(x) \leq U$ and $U(y) \leq U$, then $U\left(\frac{x+y}{2}\right) \leq U$. Hence \begin{align*}
        2\left(U - U\left(\frac{x+y}{2}\right)\right)^+ &= 2U - 2U\left(\frac{x+y}{2}\right) \\
                                                        &= 2U - U(x) - U(y) \\
                                                        &= (U - U(x))^+ + (U - U(y))^+.
    \end{align*}
    \item For the only remaining case we assume w.l.o.g. that $U(x) \leq U$ and $U(y) > U$. If $U - U(x) < U(y) - U$, then $U\left(\frac{x+y}{2}\right) > U$ and we follow the first case. If, on the other hand, $U - U(x) \geq U(y) - U$, then $U\left(\frac{x+y}{2}\right) \leq U$ and we follow the second case.\qedhere
\end{enumerate}
\end{proof}

We now have everything in place to prove our main result of this section.

\begin{theorem}
Int-SCO is NP-hard.
\end{theorem}
\begin{proof}
We now give our reduction from Min-KP to Int-SCO.

Let $\mathcal{I}_{Min-KP} = (n, c, u, U)$ be an instance of Min-KP and set $d = n$. We define $\mathcal{I}_{Int-SCO} = (T, \mathcal{X}, \norm{\cdot}, f)$ as an instance of Int-SCO with $T = 1$, $\mathcal{X} = \{0,1\}^n$, $\norm{\cdot} = 0$, and $f_1(x) = c_{SCO}'(x)$. It is easy to see that $f_1$ is non-negative. By \autoref{lemma:integer_minimization_convexity}, $\mathcal{I}_{Int-SCO}$ is a valid instance of Int-SCO.

The correctness of our construction follows from \autoref{lemma:integer_minimization}. \begin{align*}
         &x \text{ is a solution to } \mathcal{I}_{Int-SCO} \\
    \iff &x \text{ minimizes } \sum_{t=1}^T f_t(x_t) + \norm{x_t - x_{t-1}} \text{ such that } x_t \in \mathcal{X}. \\
    \iff &x \text{ minimizes } c_{SCO}'(x_1) \text{ such that } x_1 \in \{0,1\}^n. \\
    \iff &x_1 \text{ is a solution to } \mathcal{I}_{Min-KP}.
\end{align*}

Our construction is total and polynomial in the size of $\mathcal{I}_{Min-KP}$. Hence, Int-SCO is NP-hard.
\end{proof}

We observe that the above reduction can be extended to Knapsack with arbitrary bounds $m_i$ by setting $\mathcal{X}$ of $\mathcal{I}_{Int-SCO}$ to $[m_1]_0 \times \dots \times [m_n]_0$.

\subsection{Convex Body Chasing}

\subsection{Simplified Smoothed Convex Optimization}\label{section:theory:simplified_smoothed_convex_optimization}

In many applications, for example for right-sizing data centers where we are interested in determining the optimal number of servers to run at a particular time, it suffices to restrict $\mathcal{X}$ to $[m_0]_0 \times \dots \times [m_d]_0$ for some upper bound in each dimension $m \in \mathbb{N}^d$ and the switching cost $\norm{\cdot}$ to a Manhattan norm which is scaled in each dimension independently from time. To that end, we first define a restricted variant of (fractional) SCO which we term \textit{Simplified Smoothed Convex Optimization}.

\begin{problem}[Simplified Smoothed Convex Optimization (SSCO)]\label{problem:simplified_smoothed_convex_optimization}
Given a time horizon $T \in \mathbb{N}$, upper bounds $m \in \mathbb{N}^d$, switching costs $\beta \in \mathbb{R}_{>0}^d$, and a sequence of non-negative convex functions $f_t$ for $t \in [T]$, find $x \in \mathbb{R}_{\geq 0, \leq m_0} \times \dots \times \mathbb{R}_{\geq 0, \leq m_d}$ minimizing \begin{align*}
    c_{SSCO}(x) = \sum_{t=1}^T f_t(x_t) + \sum_{k=1}^d \beta_k (x_{t,k} - x_{t-1,k})^+
\end{align*}
where $x_0 = \mathbf{0}$.
\end{problem}

We observe that $c_{SSCO}$ pays the switching cost whenever $x$ increases. Decreasing $x$ does not increase the paid switching cost. This observation motivates the following lemma that shows that we could equivalently pay the switching cost for decreasing $x$.

\begin{lemma}
\label{lemma:inverse_switching_cost}
For all $T \in \mathbb{N}$ and $ x_t \in \mathbb{R}$ where $x_0 = x_{T+1} = \mathbf{0}$, the following equivalence holds:
\begin{align*}
    \sum_{t=1}^T (x_t - x_{t-1})^+ = \sum_{t=1}^T (x_t - x_{t+1})^+.
\end{align*}
\end{lemma}
\begin{proof}
The left side of the equation sums all increases in $x$ from $t \in \{0, \dots, T\}$ starting from $x_0 = \mathbf{0}$. The right side of the equation sums all decreases in $x$ from $t \in \{1, \dots, T+1\}$ ending with $x_{T+1} = \mathbf{0}$. It is easy to see that the two sums are equivalent.
\end{proof}

To complete the proof that any instance of SSCO is an instance of SCO, we have to show that our switching cost is indeed a valid norm. Given an instance $\mathcal{I}_{SSCO} = (T, m, \beta, f)$ we define the corresponding instance of SCO as $\mathcal{I}_{SCO} = (T, \mathcal{X}, \norm{\cdot}, f)$ where $\mathcal{X} = \mathbb{R}_{\geq 0, \leq m_0} \times \dots \times \mathbb{R}_{\geq 0, \leq m_d}$ and $\norm{x} = \sum_{k=1}^d \frac{\beta_k}{2} |x_k|$ as the dimension-dependently scaled Manhattan norm of $x$. It is easy to see that $\norm{\cdot}$ is indeed a valid norm. The next lemma proves that $x \in \mathcal{X}$ is a solution to $\mathcal{I}_{SCO}$ if and only if it is a solution to $\mathcal{I}_{SSCO}$.

\begin{lemma}
For any $T \in \mathbb{N}, \beta \in \mathbb{R}_{>0}^d$, and $x_t \in \mathbb{R}^d$ with $x_0 = x_{T+1} = \mathbf{0}$, the following equivalence holds:
\begin{align*}
    \sum_{t=1}^T \norm{x_t - x_{t-1}} = \sum_{t=1}^T \sum_{k=1}^d \beta_k (x_{t,k} - x_{t-1,k})^+.
\end{align*}
\end{lemma}
\begin{proof}
By \autoref{lemma:inverse_switching_cost}, the above equivalence holds iff \begin{align*}
    \sum_{t=1}^T \sum_{k=1}^d \beta_k |x_k| = \sum_{t=1}^T \sum_{k=1}^d \beta_k ((x_{t,k} - x_{t-1,k})^+ + (x_{t,k} - x_{t+1,k})^+).
\end{align*}
It is easy to see that this equivalence always holds.
\end{proof}

With the same motivation we used for the restriction of SCO to Int-SCO, we now restrict SSCO to an integral variant.

\begin{problem}[Integral Simplified Smoothed Convex Optimization (Int-SSCO)]
We define Integral Simplified Smoothed Convex Optimization analogously to SSCO with the added restriction that the points $x$ in $d$-dimensional space must be discrete, that is $x \in [m_0]_0 \times \dots \times [m_d]_0$.
\end{problem}

\citeauthor*{Albers2018} have shown for Int-SSCO in the uni-dimensional setting that the optimal competitive ratio is 3 for deterministic algorithms and 2 for randomized algorithms \cite{Albers2018}. As Int-SSCO is subsumed by Int-SCO, these bounds also hold for Int-SCO.

\subsubsection{Complexity of the Offline Problem}

We next extend our proof of NP-hardness of Int-SCO for varying $d$ to Int-SSCO. We cannot reuse our original proof as the switching cost of SSCO is required to be positive.

\begin{theorem}
\label{theorem:int_ssco_np_hardness}
Int-SSCO is NP-hard.
\end{theorem}
\begin{proof}
Again, we use a reduction from Min-KP.

Let $\mathcal{I}_{Min-KP} = (n, c, u, U)$ be an instance of Min-KP and set $d = n$. We define $\mathcal{I}_{Int-SSCO} = (T, m, \beta, f)$ as an instance of Int-SSCO with $T = 1$, $m \equiv 1$, $\beta \equiv 1$, and $f_1(x) = c_{SCO}'(x) + n - \sum_{i=1}^n x_i$.

It is easy to see that $f_1$ is non-negative. In \autoref{lemma:ssco_reduction_convexity}, we prove that $f_1$ is convex. Assuming the convexity of $f_1$, $\mathcal{I}_{Int-SSCO}$ is a valid instance of Int-SSCO.

We now prove the correctness of our construction. Again, we use \autoref{lemma:integer_minimization}. \begin{align*}
         &x \text{ is a solution to } \mathcal{I}_{Int-SSCO} \\
    \iff &x \text{ minimizes } \sum_{t=1}^T f_t(x_t) + \sum_{k=1}^d \beta_k (x_{t,k} - x_{t-1,k})^+ \text{ such that } x_t \in [m_0]_0 \times \dots \times [m_d]_0. \\
    \iff &x \text{ minimizes } f_1(x_1) + \sum_{i=1}^n x_{1,i} \text{ such that } x_1 \in \{0,1\}^n. \\
    \iff &x \text{ minimizes } c_{SCO}'(x_1) + n + \sum_{i=1}^n x_{1,i} - x_{1,i} \text{ such that } x_1 \in \{0,1\}^n. \\
    \iff &x \text{ minimizes } c_{SCO}'(x_1) \text{ such that } x_1 \in \{0,1\}^n. \\
    \iff &x_1 \text{ is a solution to } \mathcal{I}_{Min-KP}.
\end{align*}

Our construction is still total and polynomial in the size of $\mathcal{I}_{Min-KP}$. Hence, Int-SSCO is NP-hard.
\end{proof}

\begin{lemma}
\label{lemma:ssco_reduction_convexity}
$f_1$ from \autoref{theorem:int_ssco_np_hardness} is convex on $\{0,1\}^n$.
\end{lemma}
\begin{proof}
To show convexity of $f_1$, it suffices to show that $h(x) = n - \sum_{i=1}^n x_i$ is convex as the convexity of $c_{SCO}'$ was already established in \autoref{lemma:integer_minimization_convexity} and $f_1(x) = c_{SCO}'(x) + h(x)$. Further, it is enough to prove $h$ midpoint-convex as $h$ is continuous. We observe that \begin{align*}
         &&h\left(\frac{x + y}{2}\right) &\leq \frac{h(x) + h(y)}{2} \\
    \iff &&n - \sum_{i=1}^n \frac{x_i + y_i}{2} &\leq n - \frac{\sum_{i=1}^n x_i + \sum_{i=1}^n y_i}{2}
\end{align*} holds for any $x, y \in \{0,1\}^n$, proving the lemma.
\end{proof}

\subsection{Smoothed Balanced Load Optimization}

We now turn to a variant of Int-SSCO introduced by \citeauthor*{Albers2021_2} that further restricts the structure of the convex cost functions \cite{Albers2021_2}. This restriction is motivated by the usual cost model of data centers we examine in detail in \autoref{chapter:application} where the incoming load (or set of jobs) is distributed equally among all active servers.

Given a sequence of convex increasing non-negative costs $g_{t,k}(l)$ of each "instance" in dimension $k$ given its load $l$ during time slot $t$, the overall cost for dimension $k$ during time slot $t$ is given as \begin{align*}
    h_{t,k}(x,z) := \begin{cases}
        x g_{t,k}\left(\frac{l_{t,k}}{x}\right) & x > 0 \\
        \infty                                  & x = 0 \land l_{t,k} > 0 \\
        0                                       & x = 0 \land l_{t,k} = 0
    \end{cases}
\end{align*} where $l_{t,k} = \lambda_t z$ for some sequence of loads $\lambda_t \in \mathbb{N}_0$. Here, $x$ is the position in the decision space in dimension $k$, and $z \in [0,1]$ is the fraction of the load $\lambda_t$ that is "assigned" to dimension $k$ \cite{Albers2021_2}. Given the set of all possible assignments to $d$ dimensions $\mathcal{Z} := \{z \in [0,1]^d \mid \sum_{k=1}^d z_k = 1\}$, the overall hitting cost is defined as the convex optimization \begin{align}
\label{eq:sblo_hitting_cost}
    f_t(x) := \min_{z \in \mathcal{Z}} \sum_{k=1}^d h_{t,k}(x_k,z_k).
\end{align} Intuitively, the loads $\lambda_t$ are balanced across all dimensions so as to minimize cost.

\begin{problem}[Smoothed Balanced Load Optimization (SBLO)]\label{problem:sblo}
Given a time horizon $T \in \mathbb{N}$, upper bounds $m \in \mathbb{N}^d$, switching costs $\beta \in \mathbb{R}_{>0}^d$, a sequence of loads $\lambda_t \in \mathbb{N}_0$, and a sequence of convex increasing non-negative functions $g_{t,k}$ for $t \in [T], k \in [d]$, find $x \in [m_0]_0 \times \dots \times [m_d]_0$ minimizing \begin{align*}
    c_{SBLO}(x) = \sum_{t=1}^T f_t(x_t) + \sum_{k=1}^d \beta_k (x_{t,k} - x_{t-1,k})^+
\end{align*}
where $x_0 = \mathbf{0}$ and $f_t$ is given by \autoref{eq:sblo_hitting_cost}.
\end{problem}

It is easy to see that any instance of SBLO is in fact an instance of Int-SSCO.

\subsection{Smoothed Load Optimization}

Lastly, we consider an even simpler problem proposed by \citeauthor*{Albers2021} where we assume that each instance is only able to handle a single job during each time slot \cite{Albers2021}. Instead of using convex functions to model cost, we assume that cost increases linearly and independently from time with the number of active servers. In addition we impose the constraint that the number of servers must still be enough to handle the incoming load. Without this restriction the optimal strategy would always be to not run any servers at all.

\begin{problem}[Smoothed Load Optimization (SLO)]\label{problem:sblo}
Given a time horizon $T \in \mathbb{N}$, upper bounds $m \in \mathbb{N}^d$, switching costs $\beta \in \mathbb{R}_{>0}^d$, a sequence of loads $\lambda_t \in \mathbb{N}_0$, and the non-negative operating costs $l_k \in \mathbb{R}_{\geq 0}$ for $k \in [d]$, find $x \in [m_0]_0 \times \dots \times [m_d]_0$ minimizing \begin{align*}
    c_{SLO}(x) = \sum_{t=1}^T \sum_{k=1}^d l_k x_{t,k} + \beta_k (x_{t,k} - x_{t-1,k})^+
\end{align*}
where $x_0 = \mathbf{0}$ and $f_t$ is given by \autoref{eq:sblo_hitting_cost}.
\end{problem}

In contrast to our definition of SBLO, SLO balances the load implicitly among all active servers which is possible because we assume that each active server can only handle a single job during one time slot. Again, it is easy to see that SLO is an instance of SBLO by setting $g_{t,k}(l) := l_k l$.

\citeauthor*{Albers2021} show that an online algorithm for SLO cannot attain a competitive ratio smaller than $2d$ \cite{Albers2021}.
