% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Application: Right-Sizing Data Centers}\label{chapter:application}

In this chapter, we seek to derive models for right-sizing data centers based on smoothed convex optimization. We then use these models to motivate the variations of smoothed convex optimization we discuss in \cref{chapter:theory}. We begin by discussing the general features of server infrastructures. Then, we examine the modeling of \emph{operating costs}\index{operating cost} (i.e., hitting costs) and \emph{switching costs}\index{switching cost} (i.e., movement costs) in detail.

Data centers are large-scale, complex systems. Therefore, any model we examine in this chapter is an approximation. Our goal is to find models that generalize well across many data centers. When examining a specific data center, the models we discuss can be extended to yield better approximations.

\section{Architectures}\label{section:application:architectures}

We begin by revisiting the characteristics by which the design of data centers varies.

\paragraph{Speed-Scalability} For our data center model, it is natural to assume that the servers are speed scalable. That is, their utilization can vary from idling at 0\% utilization to full load at 100\% utilization. Furthermore, we assume that server utilization scales linearly with its load as this is required to maintain a steady quality of service~\cite{Bansal2015}.

\paragraph{Energy} There has been much recent work on modeling the energy consumption of a data center as a function of the speed of individual servers. We discuss these approaches in detail in \cref{section:application:operating_cost:energy}. However, in many cases, the ecological and economic cost of energy does not remain constant but fluctuates over time. More importantly, at no point in time is the energy cost a linear function of energy consumption because many data centers have quotas for each energy source~\cite{Miller2021}. For example, there may only be a limited supply of renewable energy. Once the energy consumption of our data center exceeds this supply, it has to resort to different sources of energy with different costs. Recently, a trend has also been for data centers to produce their own renewable energy~\cite{Lin2012}. In this case, this renewable energy is significantly cheaper than any energy purchased after energy consumption exceeds energy production. If, in contrast, more energy is produced than is consumed, some energy may be sold depending on the energy grid's state.

\paragraph{Homogeneity and Heterogeneity} When the data center right-sizing problem was first introduced, approaches were focused on homogeneous data centers. In a \emph{homogeneous}\index{homogeneous data center} data center, all servers are of the same type. We say that a server is of a different type than another server if their operating costs or switching costs differ significantly. In any such scenario where we have multiple server types, the data center is \emph{heterogeneous}\index{heterogeneous data center}. It is easy to see that each server type resembles one dimension in our smoothed optimization. While a homogeneous data center model is much simpler, most data centers are heterogeneous in practice, a trend that is projected to intensify~\cite{Jin2016}. Heterogeneity may arise naturally as defect servers of a homogeneous data center are replaced by newer servers. However, the primary advantage of heterogeneous architectures is that certain tasks can be delegated to specialized servers~\cite{Jin2016}. For example, CPUs and GPUs may be used within the same data center, but GPUs should only perform massive parallel computations as CPUs are faster when tasks cannot be parallelized easily~\cite{Shan2006}. The differing power-performance relationships of multiple server types are another benefit of heterogeneous architectures~\cite{Jin2016}.

\paragraph{Size} In principle, the right-sizing data center problem only admits integral solutions as, at any time, we can only run an integral number of servers of each type. However, if the size of our data center is large in each dimension, it is reasonable to use fractional solutions as an approximation. Typically, data centers fulfill this requirement. Lately, the surge in hyperscale facilities indicates a trend towards larger data centers~\cite{Jones2018}. For this reason, we discuss integral as well as fractional solutions in our analysis.

\paragraph{Reliability and Availability} Many services must satisfy specific requirements regarding reliability and availability, which are often key components of \emph{service level agreements}\index{service level agreement} (SLAs)~\cite{Lin2011}. Such requirements can be enforced as hard constraints using the decision space by requiring a minimum number of active servers per server type in our model. As our model only chooses the number of servers of some type, the algorithm can freely choose the active servers between all servers according to some guidelines to meet the requirements. However, choosing a decision space that is too tight may reduce the cost-saving potential. Therefore, an alternative approach is to use operating costs (discussed in \cref{section:application:operating_cost}) as softer constraints, for example, by enforcing a maximum utilization on servers of type $k$ that is less than some $\theta_k < 100\%$. Availability requirements for specific jobs can also be encoded into the revenue loss as a function of average job delay.

\paragraph{Networks} Most of our analysis is focused on the case of a single data center. However, the problem of deciding where to route incoming loads within a network of data centers so as to minimize the overall cost acutely relevant~\cite{Miller2021}. For example, if data centers produce their own renewable energy, the cost of energy at each individual data center is likely to vary drastically over time as weather conditions shift~\cite{Lin2012}. Therefore, previous studies focusing on individual data centers found that wind and solar can only be used with large-scale storage due to their intermittency~\cite{Gmach2010, Gmach2010_2}. Nevertheless, \citeauthor*{Lin2012}~\cite{Lin2012} showed that by running a network of data centers in separate locations, the adverse effects of renewable energy production could largely be avoided as the availability of solar and wind can be aggregated across locations. In \cref{section:application:dynamic_routing}, we show how our cost model can be extended to support geographical load balancing across a network of data centers.

\section{Dispatching}\label{section:application:dispatching}

The modeling of load is the core of our data center model. We say that a \emph{load profile}\index{load profile} of our system during time slot $t$ is a vector $\lambda_t \in \mathbb{N}_0^e$ where $e$ is the number of job types. In \cref{section:application:dispatching:multiple_load_types}, we give more concrete examples of varying job types, but generally, jobs are of different types when their cost model is different. For now, we assume that the processing time of all jobs on any server type takes exactly one time slot. In \cref{section:application:dynamic_duration}, we discuss how this approach can be extended to jobs with a dynamic duration (per server type).

We denote by $m_k \in \mathbb{N}$ the maximum number of available servers of type $k$ and by $d$ the number of server types. Our decision space is therefore given as $\mathcal{X} := \mathbb{R}_{\geq 0, \leq m_0} \times \dots \times \mathbb{R}_{\geq 0, \leq m_d}$. Further, we denote by $l_k^{\text{max}} \in \mathbb{N}$ the maximum number of jobs a server of type $k$ can process in a single time slot.

We call a load profile $\lambda_t$ \emph{feasible}\index{feasible load profile} if \begin{align}
    \sum_{i=1}^e \lambda_{t,i} \leq \sum_{k=1}^d l_k^{\text{max}} m_k =: \lambda^{\text{max}}.
\label{eq:feasible_load_profiles}
\end{align} In words, a load profile is feasible if we can process all incoming jobs by using all available servers. In our subsequent analysis, we assume that all load profiles are feasible. This is not a restriction as, in practice, if a load profile is not feasible, one would have to delay a large enough selection of jobs to an upcoming time slot until the feasibility of the current load profile is achieved.

\subsection{Optimal Load Balancing}\label{section:application:dispatching:optimal_load_balancing}

To begin with, we consider a data center with homogeneous loads, so by \cref{eq:feasible_load_profiles}, we have $\lambda_t \in [\lambda^{\text{max}}]_0 = \{0, 1, \dots, \lambda^{\text{max}}\}$. As we discussed in \cref{section:application:architectures}, energy consumption depends on server speed which in turn depends on the number of available servers $x_t \in \mathcal{X}$ (determined by the algorithm) and the load profile $\lambda_t$ (determined by an adversary). Therefore, it is natural to ask how we can optimally distribute the load across the available servers. Let $g_{t,k} : [0,l_k^{\text{max}}] \to \mathbb{R}_{\geq 0}$ be a convex increasing non-negative function representing the cost incurred by operating a server of type $k$ during time slot $t$ with a load of $l \in [0,l_k^{\text{max}}]$. We set $g_{t,k}(l) = \infty$ for $l > l_k^{\text{max}}$. The utilization (or speed) of a server of type $k$ with a load of $l$ is then given as $s_k(l) := l / l_k^{\text{max}} \in [0,1]$, assuming that the speed of a server is linearly proportional to its load.

We first consider the homogeneous setting. In the homogeneous case, we write $g_t := g_{t,1}$. We discuss concrete functions in \cref{section:application:operating_cost}, but we assume that $g_t$ can be any non-negative convex function for this section. Disregarding switching costs, we obtain the following optimization for the homogeneous setting: \begin{align*}
    \min_{x_t \in \mathcal{X}} \quad &\sum_{t=1}^T \sum_{i=1}^{x_t} g_t(l_{t,i}) \\
    \text{subject to}        \quad &\sum_{i=1}^{x_t} l_{t,i} = \lambda_t
\end{align*} where $l_{t,i} \in \mathbb{R}_{\geq 0}$ denotes the number of jobs processed by server $i$ during time slot $t$. \citeauthor*{Lin2011}~\cite{Lin2011} showed that for fixed $x_t$ the remaining dispatching problem is convex. The optimal dispatching rule $l_{t,i}^*$ is $\lambda_t / x_t$ for all $i \in [x_t]$, implying that given $x_t$, it is optimal to balance load evenly across all servers. \citeauthor*{Albers2021_2}~\cite{Albers2021_2} prove this fact using Jensen's inequality. We, therefore, define our overall operating cost as \begin{align}\label{eq:homogeneous_load_balancing}
    f_t(x) := x g_t\left(\frac{\lambda_t}{x}\right).
\end{align} It is easy to see that this definition of $f_t$ is jointly convex in $\lambda_t$ and $x$. Crucially, this is an approximation as we did not impose the restriction that job arrival rates must be integral, which is required in practice.

In the heterogeneous setting, it is easy to see that there is no single optimal dispatching rule. However, our analysis implies that the optimal dispatching strategy is to load balance within one server type, even in the heterogeneous setting~\cite{Albers2021_2}. We define the operating cost for servers of type $k$ during time slot $t$ as \begin{align}\label{eq:heterogeneous_load_balancing_unit}
    h_{t,k}(x,z) := \begin{cases} 
        x g_{t,k}\left(\frac{l_{t,k}}{x}\right) & x > 0 \\
        \infty                                  & x = 0 \land l_{t,k} > 0 \\
        0                                       & x = 0 \land l_{t,k} = 0
    \end{cases}
\end{align} where $l_{t,k} = \lambda_t z$, $x$ is the number of active servers of type $k$, and $z \in [0,1]$ is the fraction of the job volume $\lambda_t$ that is assigned to server type $k$~\cite{Albers2021_2}. As $g_{t,k}$ is convex and increasing it follows that $h_{t,k}$ too is jointly convex in $\lambda_t$ and $x$. Given the set of all possible job assignments to a collection of $d$ different server types $\mathcal{Z} := \{z \in [0,1]^d \mid \sum_{k=1}^d z_k = 1\}$, the overall operating cost can be defined as the convex optimization \begin{align}\label{eq:heterogeneous_load_balancing}
    f_t(x) := \min_{z \in \mathcal{Z}} \sum_{k=1}^d h_{t,k}(x_k,z_k).
\end{align} It is easy to see that \cref{eq:homogeneous_load_balancing} is equivalent to \cref{eq:heterogeneous_load_balancing} for $d = 1$.

\Cref{eq:heterogeneous_load_balancing} can be computed using the convex program \begin{alignat}{2}\label{eq:heterogeneous_load_balancing_constrained_convex_program}
    &\min_{z \in [0,1]^d} &\qquad&\sum_{k=1}^d h_{t,k}(x_k,z_k) \\
    &\textrm{subject to}  &      &\sum_{k=1}^d z_k = 1.
\end{alignat} A linear-equality-constrained problem can be solved via a change of variable~\cite{Singer2016}. \Cref{eq:heterogeneous_load_balancing_constrained_convex_program} using an equality constraint is equivalent to a $(d-1)$-dimensional convex program as the last dimension $d$ is completely determined by the dimensions $1$ through $d-1$: \begin{alignat}{2}\label{eq:heterogeneous_load_balancing_convex_program}
    &\min_{z \in [0,1]^{d-1}} &\qquad&\sum_{k=1}^{d-1} h_{t,k}(x_k,z_k) + h_{t,d}(x_d,z_d) \\
    &\textrm{subject to}  &      &\sum_{k=1}^{d-1} z_k \leq 1 \nonumber
\end{alignat} where $z_d = 1 - \sum_{k=1}^{d-1} z_k$. \Cref{eq:heterogeneous_load_balancing_convex_program} can easily be computed numerically using a standard solver for convex programs.

\subsection{Multiple Job Types}\label{section:application:dispatching:multiple_load_types}

The problem becomes harder when we consider heterogeneous loads. However, as we have seen in \cref{section:application:architectures}, multiple \emph{job types}\index{job type} are often required in practice, for example, to distinguish different processing speeds of CPUs and GPUs for different tasks. Instead of determining the optimal assignment fractions of the total load to server types, we now need to determine the optimal assignment of fractions of individual job types to server types. To that end, we define the set of such assignments as \begin{align*}
    \mathcal{Z}_t := \left\{z_t \in [0,1]^{e^d} \mid \forall i \in [e].\ \lambda_t > 0 \implies \sum_{k=1}^d z_{t,k,i} = \frac{\lambda_{t,i}}{\lambda_t}\right\}
\end{align*} where $\lambda_t := \sum_{i=1}^e \lambda_{t,i}$. Here, $z_{t,k,i}$ is the fraction of jobs of type $i$ assigned to servers of type $k$ during time slot $t$. $\lambda_{t,i} / \lambda_t$ is the fraction of jobs of type $i$ at time $t$.

We continue to use optimal load balancing similarly to \cref{eq:heterogeneous_load_balancing_unit} to distribute load evenly across all servers of the same type. However, we introduce an additional cost that is paid per job of type $i$ that is processed on a server of type $k$. Our new operating cost for servers of type $k$ during time slot $t$ thus becomes \begin{align}\label{eq:multiple_load_types_load_balancing_unit}
    h_{t,k}(x,z) := \begin{cases} 
        x g_{t,k}\left(\frac{l_{t,k}}{x}\right) + \sum_{i=1}^e l_{t,k,i} q_{t,k,i}\left(\frac{l_{t,k}}{x}\right) & x > 0 \\
        \infty                                                                                                   & x = 0 \land l_{t,k} > 0 \\
        0                                                                                                        & x = 0 \land l_{t,k} = 0
    \end{cases}
\end{align} where $l_{t,k,i} = \lambda_{t,i} z_i$, $l_{t,k} = \sum_{i=1}^e l_{t,k,i}$, $x$ is the number of active servers of type $k$, and $z \in [0,1]^e$ are the fractions of the job volumes $\lambda_{t,i}$ that are assigned to server type $k$. Here, $q_{t,k,i}(l)$ is the convex increasing non-negative cost incurred by processing a job of type $i$ on a server of type $k$ during time slot $t$ when a total of $l$ jobs are processed on this server. We discuss this cost in greater detail in \cref{section:application:operating_cost}. $g_{t,k}(l)$ remains the convex increasing non-negative operating cost of a server of type $k$ during time slot $t$ under total load $l$. It is easy to see that this definition of $h$ remains jointly convex in $\lambda_t$ and $x$. We still set $g_{t,k}(l) = \infty$ if $l > l_k^{max}$.

We can now define the overall operating cost analogously to \cref{eq:heterogeneous_load_balancing} as the convex optimization \begin{align}\label{eq:multiple_load_types_load_balancing}
    f_t(x) := \min_{z \in \mathcal{Z}_t} \sum_{k=1}^d h_{t,k}(x_k,z_k).
\end{align}

Again, we observe that for $e = 1$ \cref{eq:multiple_load_types_load_balancing} is equivalent to \cref{eq:heterogeneous_load_balancing} by setting $q_{t,k,1} \equiv 0$. Henceforth, we restrict our analysis to the model from \cref{eq:multiple_load_types_load_balancing}.

We can use a similar approach to \cref{eq:heterogeneous_load_balancing_convex_program} to simplify \cref{eq:multiple_load_types_load_balancing} to a $(d-1)$-dimensional convex optimization: \begin{alignat}{2}\label{eq:multiple_load_types_load_balancing_convex_program}
    &\min_{z \in [0,1]^{d-1}} &\qquad&\sum_{k=1}^{d-1} h_{t,k}(x_k,z_k) + h_{t,d}(x_d,z_d) \\
    &\textrm{subject to}  &      &\sum_{k=1}^{d-1} z_{k,i} \leq \lambda_{t,i} / \lambda_t \qquad\forall i \in [e]\quad\text{if }\lambda_t > 0 \nonumber
\end{alignat} where $z_{d,i} = \lambda_{t,i} / \lambda_t - \sum_{k=1}^{d-1} z_{k,i}$ if $\lambda_t > 0$ and $z_{d,i} = 0$ otherwise. Again, \cref{eq:multiple_load_types_load_balancing_convex_program} can be computed using a standard solver for convex programs.

\section{Operating Cost}\label{section:application:operating_cost}

Our next goal is to model the operating cost of servers in a data center and the cost of powering up and powering down servers. Note that reducing the energy consumption of a data center also reduces cooling and power distribution costs~\cite{Lin2011, Clark2005}. It is, therefore, reasonable to focus on server-specific costs.

Given our analysis from \cref{section:application:dispatching}, we seek to determine the server-dependent cost $g_{t,k}(l)$ and the job-dependent cost $q_{t,k,i}(l)$ given $l$ jobs are processed on servers of type $k$. As introduced in \cref{chapter:introduction}, we interpret the server-dependent cost as \emph{energy cost}\index{energy cost} and the job-dependent costs as \emph{revenue loss}\index{revenue loss}.

\paragraph{Energy Cost} Energy cost is a function of energy consumption which in turn is a function of server utilization. We have seen in \cref{section:application:dispatching:optimal_load_balancing} that the server utilization of a server of type $k$ given a server load of $l$ is $l / l_k^{\text{max}}$ where we defined $l_k^{\text{max}}$ as the maximum number of jobs a server of type $k$ can process in a single time slot. Let $e_{t,k}(s)$ be the energy cost of operating a server of type $k$ during time slot $t$ with utilization $s$. Then, \begin{align*}
    g_{t,k}(l) := e_{t,k}\left(\frac{l}{l_k^{\text{max}}}\right).
\end{align*} Some authors only consider energy costs as they assume the largest fraction of operating costs~\cite{Bansal2015}.

\paragraph{Revenue Loss} Revenue loss measures the lost revenue based on our distribution of incoming job types to server types. We model revenue loss as a convex increasing non-negative function $r_{t,i}(d)$ that describes the domain-specific revenue loss of jobs of type $i$ during time slot $t$ given an average delay of $d$. We model the average delay $d$ of jobs processed on a server of type $k$ where the total load on the server is $l$ as the convex increasing non-negative function $d_{k}(l)$. We also introduce an additional delay $\delta_{t,k,i}$ which models the constant delay incurred by processing jobs of type $i$ on servers of type $k$ during time slot $t$. Hence, we obtain \begin{align*}
    q_{t,k,i}(l) := r_{t,i}(d_{k}(l) + \delta_{t,k,i}).
\end{align*}

Typically, revenue loss is scaled linearly with delay~\cite{Lin2011}. We thus set $r_{t,i}(d) = \gamma_i \cdot d$ for factors $\gamma_i \in \mathbb{R}_{\geq 0}$.

\paragraph{} In the subsequent sections, we consider models for energy cost and delay, respectively.

\subsection{Energy}\label{section:application:operating_cost:energy}

Our goal is to model the energy cost $e_{t,k}(s)$ of a server of type $k$ during time slot $t$ based on its utilization $s$. To this end, we consider two functions. First, let $\phi_k(s)$ denote the energy consumption of a server of type $k$ with utilization $s$. Second, let $\nu_{t,k}(p)$ be the energy cost of a server of type $k$ during time slot $t$ associated with an energy consumption of $p$. We then set $e_{t,k}(s) := \nu_{t,k}(\phi_k(s))$. If the utilization $s$ exceeds the maximum allowed utilization $\theta_k \in [0,1]$ of server $k$ as described in \cref{section:application:architectures}, i.e. $\theta_k < s$, we set $e_{t,k}(s) = \infty$.

\paragraph{Energy Cost} We begin by modeling the energy cost associated with a consumption of $p$ units of energy during time slot $t$. The simplest model assigns each unit of energy the average cost during time slot $t$, which we call $c_t$. We then obtain $\nu_{t,k}(p) := c_t p$ for all $k \in [d]$ which is convex, increasing, and non-negative. If we simply want to achieve power-proportionality of the data center, it suffices to set $c \equiv 1$. We seek a more complex model in many practical applications, which we introduce at the end of this subsection and describe formally in \cref{section:application:energy_quotas}.

\paragraph{Energy Consumption} There are a variety of models for energy consumption in a data center. We give an overview of the most common models and reference additional models. To rephrase our objective, we seek to model the energy consumption of a single server based on the utilization (also referred to as speed or frequency) $s$. The energy consumption $\phi_k(s)$ can be calculated as $\delta \Phi_k(s)$ where $\delta$ is the length of a time slot and $\Phi_k(s)$ is the power consumption of a server of type $k$ with utilization $s$~\cite{Dayarathna2016}. Models of power consumption can be categorized into linear and non-linear models~\cite{Ismail2020}. In this work, we mostly restrict our analysis to linear models of which the performance is highly dependent on the chosen parameters~\cite{Ismail2020}. \citeauthor*{Ismail2020}~\cite{Ismail2020} also present more accurate non-linear and machine learning models.

An intuitive model of power consumption is discussed by \citeauthor*{Dayarathna2016}~\cite{Dayarathna2016} and \citeauthor*{Ismail2020}~\cite{Ismail2020} is \begin{align}\label{eq:energy_model:1}
    \Phi_k(s) = (\Phi_k^{\text{max}} - \Phi_k^{\text{min}})s + \Phi_k^{\text{min}}
\end{align} where $\Phi_k^{\text{max}}$ and $\Phi_k^{\text{min}}$ are the power a server of type $k$ consumes at full load and when idling, respectively. In linear power models we distinguish between the \emph{dynamic power}\index{dynamic power}, here the first term $(\Phi_k^{\text{max}} - \Phi_k^{\text{min}})s$, and the \emph{static power}\index{static power} (or leakage power), $\Phi_k^{\text{min}}$. Following the findings of \citeauthor*{Barroso2007}~\cite{Barroso2007}, we can use that generally servers consume half of their peak power when idling to simplify the above model~\cite{Ismail2020}: \begin{align}\label{eq:energy_model:2}
    \Phi_k(s) = \frac{1}{2} \Phi_k^{\text{max}} (1 + s).
\end{align}

The above models of power consumption are linear. Another frequently used model is non-linear and defined as \begin{align}\label{eq:energy_model:3}
    \Phi_k(s) = \frac{s^{\alpha_k}}{\beta_k} + \Phi_k^{\text{min}}
\end{align} where $\alpha_k > 1$ and $\beta_k > 0$ are constants~\cite{Dayarathna2016}. Here, $s^{\alpha_k}/\beta_k$ is the dynamic power and $\Phi_k^{\text{min}}$ is the static power. A variant of this model is used by \citeauthor*{Bansal2015}~\cite{Bansal2015}.

We observe that all of the above models are convex, increasing, and non-negative.

\paragraph{Energy Quotas} We mentioned the prevalence of energy quotas in many practical applications in \cref{section:application:architectures}. Up until now, we have only considered a fixed energy price per unit of energy. When we consider energy quotas, this setup changes. For example, we may produce a changing amount of renewable energy at a data center which is much cheaper than regular energy~\cite{Lin2012}. It is easy to see that computing the energy cost per server is insufficient in such a scenario. Instead, we must adjust our model from \cref{eq:multiple_load_types_load_balancing} to simultaneously calculate the energy cost across all servers (of all server types). However, we can easily model more complex energy prices within our existing framework once this adjustment is made. For example, \citeauthor*{Lin2012}~\cite{Lin2012} used a simplified model that does not take into account individual server utilization but assumes a quota of renewable energy that is assumed to be free of charge: \begin{align*}
    e_t(x) = c_{t}(x - p_t)^+
\end{align*} where $c_t$ is the average price per unit of energy during time slot $t$ and $p_t$ is the quota of free renewable energy during time slot $t$, considering only a single server type. We define $(\cdot)^+ := \max \{0, \cdot\}$. In this model, each active server consumes approximately one unit of energy. Note that here $e_t$ depends on the number of active servers $x$ allowing the consideration of quotas, whereas, in our original model, it solely depends on $l$.

This simple model could be extended by considering quotas for multiple sources of energy, considering the gain of selling unused renewable energy back to the grid, or by computing energy consumption based on the actual utilization of active servers. We present one such model in \cref{section:application:energy_quotas}.

\paragraph{Economic and Ecological Cost} Our energy quota model can be extended to model a variety of incentives where the incentives are provided by our choice of the average energy costs of energy source $i$ per unit of energy during time slot $t$ which are denoted by $c_{t,i}$. Contrary to initial intuition, the nature of these costs does not have to be purely economical. While it is reasonable to consider the cost of energy, we can extend our incentives by considering the emission of $CO_2$ equivalents per unit of energy of each energy source. Such a policy can guide towards a carbon-free makeup of energy sources across all data center locations. Such a model is of interest in many current data center networks~\cite{Hoelzle2020, Miller2021}.

\subsection{Delay}

We use queueing theory to model the queueing delay of jobs in the system. We are interested in the average delay $d_{k}(l)$ of jobs when they are processed by a server of type $k$ with a total of $l$ serviced jobs.

In our model, we consider a single service channel, our server of type $k$. We further assume that the queue's capacity is unlimited, as is the potential number of job arrivals. The latter assumption is an approximation as, in principle, we can expect a total of $l$ arrivals during time slot $t$. It is natural to assume that the arrival of jobs is Markovian, i.e., Poisson-distributed. So the interarrival times of jobs follow the exponential distribution. To remain as general as possible, the only restriction we impose on service times is that we assume they are independent. Hence, our assumptions naturally lead us to model delay based on an M/GI/1 queue.

A good model of the queueing discipline of a server is the \emph{Round Robin}\index{round robin scheduling} (RR) scheduling algorithm, where jobs are processed in turn, but when the processing of a job exceeds some time quantum, it is moved to the back of the circular queue. In many cases, however, the idealized \emph{Processor Sharing}\index{processor sharing queue} (PS) discipline is used as an approximation of RR~\cite{Lin2011, Lin2012}. In a PS queue, each job in the system is processed simultaneously at a rate inversely proportional to the current number of jobs. Therefore, the service rate is given as $C / n$ where $C$ is the server's capacity and $n$ is the current number of jobs. PS is an approximation of RR as, in general, the capacity of a server cannot be divided into real-valued parts~\cite{Virtamo2007}. However, note that this approximation echoes our simplification in \cref{section:application:dispatching:optimal_load_balancing}, leading to optimal load balancing on a per-server level.

A single server modeled by the PS discipline and operating according to Poisson-distributed arrivals has the valuable property that its queue length distribution is geometric irrespectively of the service time distribution~\cite{Aalto2007}. In other words, the average delay in a PS queue is insensitive to the service time distribution.

Let $X \sim \text{Po}(\lambda)$ be the number of arriving jobs per time unit with rate $\lambda$. The expected delay $E T$ of a PS queue is then given as \begin{align}\label{eq:avg_delay}
    E T = \frac{1/\mu}{1-\rho} = \frac{1}{\mu - \lambda}
\end{align} where $\mu = C / E X = C / \lambda$ is the service rate of the server and $\rho = \lambda / \mu$ is the parameter to the geometric queue length distribution~\cite{Virtamo2007}. The PS discipline can be considered utmost egalitarian as the average delay of any job in our system is directly proportional to the total number of jobs but does not depend on the type of the job~\cite{Virtamo2007}.

Using the model from \cref{eq:avg_delay}, the average delay of jobs processed by servers of type $k$ is given by \begin{align}\label{eq:delay}
    d_{k}(l) := \frac{1}{\mu_k - l}
\end{align} where $\mu_k$ is the service rate of a server of type $k$ and $l$ is the total number of jobs processed by the server. Assuming that a server can only process a single job during a time slot, i.e. $C = 1$, the service rate is given as $\mu_k = 1$, a model previously used by \citeauthor*{Lin2011}~\cite{Lin2011, Lin2012}. In \cref{section:application:dynamic_duration}, we discuss how the delay can be obtained in a more general setting where the duration of jobs is heterogeneous.

Given average delay $d$, we use a natural model of the revenue loss similar to the proposal of \citeauthor*{Lin2011}~\cite{Lin2011} which is given by $r_{t,i}(d) := (d - \delta_i)^+$ where $\delta_i$ denotes the minimal detectable delay of jobs of type $i$. For $\delta_i = 0$ for all $i \in [e]$, this model is the same as the model of~\cite{Lin2012}. Note that our definitions of $d_k$ and $r_{t,i}$ are convex, increasing, and non-negative.

\section{Switching Cost}\label{section:application:switching_cost}

The switching cost can be understood as the cost associated with transitioning a server from a sleep state to the active state and vice versa. This switching cost is independent of time but may depend on the type of server that is transitioned. Hence, we naturally arrive at the restriction which we also impose on simplified smoothed convex optimization (\cref{problem:simplified_smoothed_convex_optimization}) where we introduce dimension-dependent transition costs $\beta_k$ and define the total switching cost as a generalization of the $\ell_1$-norm \begin{align*}
    \sum_{k=1}^d \beta_k (X_{t,k} - X_{t-1,k})^+
\end{align*} where $X_0 = X_{T+1} = \mathbf{0}$. Note that in this model, we only pay the transition cost $\beta_k$ when a server is powered up. As all servers have to arrive in the sleep state eventually, we can fold the cost of powering down a server into $\beta_k$, i.e., $\beta_k$ represents the cost associated with powering up and powering down a server. Additionally, we assume that the operating cost associated with a sleeping server is $0$. This restriction is reasonable when we interpret the sleep state as a server that is fully powered down.

\paragraph{Model} \citeauthor*{Lin2011}~\cite{Lin2011} identify four costs contributing to the transition cost: First, (1) the additional energy consumed by toggling a server on and off $\epsilon_k$, (2) the delay in migrating connections or data $\delta_k$, for example, when using virtual machines, (3) wear-and-tear costs of toggling a server $\tau_k$, and (4) the perceived risk $\rho_k$ associated with toggling a server of type $k$. We thus model the transition cost as \begin{align*}
    \beta_k := c_k(\epsilon_k + \delta_k \Phi_k^{\text{max}}) + \tau_k + \rho_k
\end{align*} where $c_k$ is the average cost of energy for servers of type $k$.

When only (1) and (2) are considered, $\beta_k$ is on the order of migrating network state~\cite{Chen2008}, storage state~\cite{Thereska2009}, or a large virtual machine~\cite{Clark2005} which roughly translates to the cost of operating a server of type $k$ for a few seconds to several minutes~\cite{Lin2011}. Including (3) increases $\beta_k$ to the order of operating a server of type $k$ for an hour~\cite{Bodik2008}. Our model of risk associated with toggling a server is the vaguest. \citeauthor*{Lin2011}~\cite{Lin2011} suggest that if this risk is included, $\beta_k$ is on the order of operating a server of type $k$ for several hours.

We call $\xi_k := \beta_k / e_k(0)$ the \emph{normalized switching cost}\index{normalized switching cost} where $e_k(0) = c_k \delta \Phi_k^{\text{min}}$ is the average energy cost of an idling server of type $k$ in a single time slot. Hence, $\xi_k$ approximately measures the minimum duration a server must be asleep to outweigh the switching cost. Competitive algorithms typically wait until this cost is amortized before taking action. Therefore, the normalized switching cost can be used to review how a chosen switching cost relates to the remainder of the model.

\section{Dynamic Routing}\label{section:application:dynamic_routing}

For dynamic routing, also called \emph{geographical load balancing}\index{geographical load balancing}, we consider a network of $\iota$ data centers. We are interested in dispatching incoming jobs from $\zeta$ different geographically centered locations to the data centers and simultaneously right-sizing each data center (i.e., determining the number of active servers)~\cite{Lin2012}. Let $d$ be the number of server types and $e$ the number of job types. We observe that this problem can be translated to a pure data center right-sizing problem by considering $\iota \cdot d$ dimensions and a total of $\zeta \cdot e$ load types. A dimension $(j,k)$ thus encompasses a data center $j \in [\iota]$ and a server type $k \in [d]$. A \emph{load type}\index{load type} $(s,i)$ encompasses a source $s \in [\zeta]$ and a job type $i \in [e]$.

Costs can be modeled in the same way that was presented in \cref{section:application:operating_cost}. Here, $\delta_{t,(j,k),(s,i)}$ can be interpreted as the network delay incurred by routing a request from source $s$ to data center $j$ during time slot $t$~\cite{Lin2012}.

\section{Dynamic Duration}\label{section:application:dynamic_duration}

In some scenarios, job types may incur not only different costs (as covered in \cref{section:application:dispatching:multiple_load_types}) but also have varying duration. We denote by $\delta$ the length of a time slot and by $\eta_{k,i}$ the average processing time of a job of type $i$ on a server of type $k$ assuming the server operates at full utilization. We impose the natural assumption that for any job type $i \in [e]$ there exists a server type $k \in [d]$ such that $\eta_{k,i} \leq \delta$.

If this were not the case, we could not guarantee that the jobs of this type finish in time on some server before servers are assigned to a new set of jobs at the beginning of the next time slot. This model can be extended to support jobs that reach across multiple time slots by keeping track of when jobs will be finished and extending each newly arriving load profile with all unfinished jobs. It can then be enforced that those jobs must be processed on the same server type throughout their lifetime by setting the hitting cost appropriately.

\paragraph{Sub-Time Jobs} To translate the problem that considers dynamic job durations to the problem discussed in \cref{section:application:dispatching:multiple_load_types}, we interpret the length of time during which a server operates at full utilization to process its assigned jobs as the (fractional) number of \emph{sub-time jobs}\index{sub-time jobs}. During time slot $t$ for a server type $k$ with $x$ active servers, the number of sub-time jobs that are processed on a single server of type $k$ is given as $\sum_{i=1}^e l_{t,k,i} \eta_{k,i}$. Note that this is similar to our previous definition of $l_{t,k}$ but is scaled with the time jobs take to be processed. \Cref{fig:dynamic_job_duration} shows how an assignment of sub-time jobs to a server relates to an assignment of jobs.

\begin{figure}
    \centering
    \input{thesis/figures/sub_time_jobs}
    \caption{Relationship of jobs and sub-time jobs. Shown is an assignment of four jobs with equal runtime to a server with $l_{\text{max}} = 5$. For some fixed $\delta$, the jobs are translated to sub-time jobs by setting $\eta = \delta / l_{\text{max}}$. Jobs are visualized by the upper bar, their corresponding sub-time jobs are displayed by the lower bar. The figure shows that the number of sub-time jobs is proportional to the processing time of a job. As servers are assumed to be dynamically speed-scalable, the utilization of a server during some time slot is proportional to the number of sub-time jobs it is assigned to.}
    \label{fig:dynamic_job_duration}
\end{figure}

\paragraph{Utilization} The utilization of a server of type $k$ given an assignment of $l$ sub-time jobs is given as $l / \delta$. We set $g_{t,k}(l) = \infty$ if $l > \delta$. We also add the processing time to the perceived delay until a job is finished by increasing $\delta_{t,k,i}$ by $\eta_{k,i}$.

\paragraph{Delay} To model the average delay, we use the average job duration to determine the service rate. Formally, we set $\mu$ from \cref{eq:avg_delay} to $\mu = 1 / E Y$ where the expected duration of a job on a server of type $k$ during time slot $t$ is \begin{align*}
    E Y = \begin{cases}
        \sum_{i=1}^e l_{t,k,i} \eta_{k,i} / \sum_{i=1}^e l_{t,k,i} & \sum_{i=1}^e l_{t,k,i} > 0 \\
        0 & \text{otherwise}.
    \end{cases}
\end{align*} Note that we normalized the service rate to unit time. The arrival rate is therefore given as the number of jobs handled on a single server of type $k$ divided by the length of a time slot, i.e. $\lambda = \frac{1}{\delta} \sum_{i=1}^e l_{t,k,i} / X_{t,k}$. When servers of type $k$ receive no load, i.e., $\sum_{i=1}^e l_{t,k,i} = 0$, we set their associated delay to zero. For $\sum_{i=1}^e l_{t,k,i} > 0$ and using our original model from \cref{eq:delay}, we obtain the average delay across all jobs processed on a server of type $k$ during time slot $t$ as \begin{align*}
    d_{t,k} := \begin{cases}
        1 / \left(\frac{1}{E Y} - \lambda\right) & \frac{1}{E Y} > \lambda \\
        \infty & \text{otherwise}.
    \end{cases}
\end{align*} Here, we use our assumption that any job can be processed within a single time slot on servers of some type. Note that if $\eta_{k,i} \to \delta$ for some server type $k$ and job type $i$ the average delay will go to infinity as the build-up of long job queues becomes more likely.

\paragraph{Prohibitions} If we want to prohibit altogether that jobs of type $i$ are processed on servers of type $k$, it suffices to set $\delta_{t,k,i} = \infty$ as the revenue loss $r_{t,i}$ is assumed to be convex.

\section{Energy Quotas}\label{section:application:energy_quotas}

We motivated energy quotas in \cref{section:application:operating_cost:energy} and are now ready to present a model that allows for the required flexibility when modeling energy cost. To be as general as possible, we continue to assume a network of $\iota$ data centers with $d$ server types, resulting in a total of $\iota \cdot d$ dimensions. We also continue to examine $\zeta \cdot e$ load types where $\zeta$ is the number of geographically centered job sources and $e$ is the number of job types. We now extend our model from \cref{eq:multiple_load_types_load_balancing} to \begin{align*}
    f_t(x) := \min_{z \in \mathcal{Z}_t} \sum_{j=1}^{\iota} \left(e_{t,j}(x,z) + \sum_{k=1}^{d} h_{t,(j,k)}(x_{(j,k)},z_{(j,k)})\right)
\end{align*} where $e_{t,j}(x,z)$ is the total energy cost of data center $j$ during time slot $t$. $h_{t,(j,k)}(x,z)$ reduces to \begin{align*}
    \sum_{s=1}^{\zeta} \sum_{i=1}^e l_{t,(j,k),(s,i)} q_{t,(j,k),(s,i)}\left(\frac{l_{t,(j,k)}}{x}\right)
\end{align*} for $x > 0$ where $l_{t,(j,k),(s,i)} = \lambda_{t,(s,i)} z_{(s,i)}$ and $l_{t,(j,k)} = \sum_{s=1}^{\zeta} \sum_{i=1}^e l_{t,(j,k),(s,i)} \eta_{(j,k),(s,i)}$. The other cases remain as described in \cref{eq:multiple_load_types_load_balancing_unit}. Note that these definitions of $f_t$ and $h_{t,(j,k)}$ are simply adaptations of our previous definitions from \cref{section:application:dispatching} and, in particular, are convex, increasing, and non-negative.

Given $x \in \mathcal{X}$ and $z \in \mathcal{Z}$, in data center $j$, the average utilization of active servers of type $k$ during time slot $t$ is given as $l_{t,(j,k)} / x_{(j,k)}$. Hence, using optimal load balancing, we obtain the total energy consumption of data center $j$ with \begin{align*}
    \phi'_j(x,z) := \sum_{k=1}^{d} x_{(j,k)} \phi_{k}\left(\frac{l_{t,(j,k)}}{x_{(j,k)} \cdot \delta}\right)
\end{align*} for $x > 0$. The total energy cost of data center $j$ during time slot $t$ is therefore given as $e_{t,j}(x,z) := \nu_{t,j}(\phi'_j(x,z))$. We observe that, on the condition that $\nu_{t,j}$ and $\phi_k$ are convex increasing non-negative functions, the same holds for $e_{t,j}$. $\nu_{t,j}$ now receives the entire energy consumption at a location during time slot $t$ as input.

\paragraph{Maximum Quotas} We are thus able to model more complex energy costs. We consider by $p_{t,i,j} \in \mathbb{R}_{\geq 0} \cup \{\infty\}$ the energy from source $i \in [\xi]$ available at data center $j$ during time slot $t$. We denote by $c_{t,i}$ the average cost per unit of energy of energy source $i$ during time slot $t$ and assume without loss of generality that $c_{t,1} \leq c_{t,2} \leq \cdots$ holds for $t \in T$. A reasonable model of energy cost would then be to use the sources of energy in order of cost until the energy demand is satisfied. We define \begin{align*}
    \delta_{t,i,j} := (p - \sum_{i'=1}^{i-1} p_{t,i',j})^+
\end{align*} as the remaining energy requirement of data center $j$ during time slot $t$ after all energy sources up to source $i$ were used. Our model is then given by \begin{align*}
    \nu_{t,j}(p) := \sum_{i=1}^{\xi} c_{t,i} \min\{\delta_{t,i,j}, p_{t,i,j}\}
\end{align*} where we assume that the energy supply is \emph{sufficient}\index{sufficient energy supply}, i.e. $p \leq \max_{z \in \mathcal{Z}_t} \phi_j(m,z) \leq \sum_{i=1}^{\xi} p_{t,i,j}$ where we defined $m$ as the vector of upper bounds of each dimension of the decision space. It is easy to see that $\nu_{t,j}$ is continuous, increasing, and convex.

\paragraph{Making Profit} Let us now assume that some energy sources $i \in [\xi]$ are produced at data center $j$, and by selling unused supply, we make an average profit of $u_{t,i}$ per unit of energy during time slot $t$. We set $u_{t,i} = 0$ for all external energy sources. Again, we assume without loss of generality that $c_{t,1} + u_{t,1} \leq c_{t,2} + u_{t,2} \leq \cdots$ holds for $t \in T$. The energy cost of this extended model is then given by \begin{align*}
    \nu_{t,j}(p) &:= \sum_{i=1}^{\xi} c_{t,i} \min\{\delta_{t,i,j}, p_{t,i,j}\} - u_{t,i} (p_{t,i,j} - \delta_{t,i,j})^+ \\
                 &= \sum_{i=1}^{\xi} (c_{t,i} + u_{t,i}) \min\{\delta_{t,i,j}, p_{t,i,j}\} - \sum_{i=1}^{\xi} u_{t,i} p_{t,i,j}
\end{align*} where we continue to assume that the energy supply is sufficient. As the first sum is convex and increasing and as the subtracted sum is constant, we know that also $\nu_{t,j}$ must be convex and increasing. For the definition to be non-negative, we require $\sum_{i=1}^{\xi} u_{t,i} p_{t,i,j}$ to be less or equals to $\sum_{i=1}^{\xi} (c_{t,i} + u_{t,i}) \min\{\delta_{t,i,j}, p_{t,i,j}\}$. In words, we require that the possible profit does not exceed the total energy cost of a data center, whether this energy cost is related to energy sources with an associated cost or energy sources with an associated profit that are used rather than sold. Note that this requirement is natural in the context of data centers, as the main purpose behind on-site energy production is to sustain the data center and interaction with the grid merely happens to offset variances in power generated on-site.

\paragraph{Minimum Quotas} One could also imagine a scenario where we seek to impose minimum quotas, requiring that some energy sources make up at least a certain fraction of the total energy use of a data center. While such quotas are relevant, as research on green data centers shows (discussed in \cref{section:application:operating_cost:energy}), they are inherently soft. In contrast, the maximum quotas were hard as they enforced a physical limitation of energy supply. Hence, in most cases, it is beneficial to model tendencies towards some energy sources using costs rather than strict quotas to largely decouple the energy cost model from energy availability. The cost model can then be adapted to result in the desired makeup of energy sources.

% Suppose now that in addition for some energy sources $i \in I$ we impose a quota $q_{t,i,j} \in [0,1]$ requiring that energy from source $i$ must make up at least a fraction of $q_{t,i,j}$ of the total energy use of data center $j$ during time slot $t$. Naturally, the sum of all quotas must not exceed $1$, i.e. $\sum_{i \in I} q_{t,i,j} \leq 1$ for all $t \in T, j \in [\iota]$. We also assume that the energy supply is sufficient to fulfill the quotation, i.e. $p_{t,i,j} \geq q_{t,i} p_{t,j}$ where $p_{t,j}$ is the energy consumption of data center $j$ during time slot $t$. In our cost model we first fulfill the imposed quotas and then fallback to our previous model: \begin{align*}
%     \nu_{t,j}(p) := \sum_{i \in I} c_{t,i} q_{t,i,j} p + \sum_{i \in I} c_{t,i} \min\{\delta_{t,i,j}, p_{t,i,j} - q_{t,i,j} p\} - u_{t,i} (p_{t,i,j} - \delta_{t,i,j})^+
% \end{align*} where \begin{align*}
%     \delta_{t,i,j} = (p - \sum_{i \in I} q_{t,i,j} p - \sum_{\substack{i' \in I, \\ i' < i}} p_{t,i',j})^+
% \end{align*} models the remaining energy requirement after all minimum quotas were satisfied and all energy sources up to source $i$ were used. We continue to assume that energy supply is sufficient. In most cases, however, it is beneficial to model tendencies towards some sources of energy using costs rather than strict quotas to largely decouple the energy cost model from energy availability.

\paragraph{} We have seen an expressive framework for cost models that specifically model data centers but are general enough to support a network of heterogeneous data centers with heterogeneous loads and flexible energy costs. This reaches our main goal for this chapter.